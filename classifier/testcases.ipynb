{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from classifier import Darknet53\n",
    "\n",
    "def test_output_shape():\n",
    "    # Create a random tensor with the desired dimensions\n",
    "    input_tensor = torch.randn(1, 3, 256, 256)  # Assuming input shape is (batch_size, channels, height, width)\n",
    "    input_tensor_batch = torch.randn(10, 3, 256, 256)\n",
    "\n",
    "    # Initialize the classifier\n",
    "    classifier = Darknet53()\n",
    "\n",
    "    # Pass the input tensor through the classifier\n",
    "    output = classifier(input_tensor)\n",
    "    output_batch = classifier(input_tensor_batch)\n",
    "\n",
    "    # Check if the output tensor has the expected dimensions\n",
    "    assert output.shape == (1, 1000)  # Replace `num_classes` with the actual number of classes\n",
    "    assert output_batch.shape == (10, 1000) \n",
    "\n",
    "test_output_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test single and batch inputs. Output shape should have proper dimensions of 1x1000 for the 1000 classes in the ImageNet-1k dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random input tensor\n",
    "input_tensor = torch.randn(1, 3, 256, 256)  # Assuming input shape is (batch_size, channels, height, width)\n",
    "\n",
    "# Create a random target tensor\n",
    "target_tensor = torch.randn(1, 1000)  # Assuming target shape is (batch_size, num_classes)\n",
    "\n",
    "# Initialize the classifier\n",
    "classifier = Darknet53()\n",
    "\n",
    "# Forward pass\n",
    "output = classifier(input_tensor)\n",
    "\n",
    "# Calculate the loss\n",
    "loss = torch.nn.functional.mse_loss(output, target_tensor)\n",
    "\n",
    "# Backward pass\n",
    "loss.backward()\n",
    "\n",
    "# Check if the gradients are updated\n",
    "for param in classifier.parameters():\n",
    "    assert param.grad is not None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test to see if dataset objects load Image net traning and validation directories correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imagenet import ImageNetDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def transform_image(image):\n",
    "    # Rescale the image to 256x256 pixels\n",
    "    image = image.resize((256, 256))\n",
    "    return image\n",
    "\n",
    "TRAINING_IMAGE_PATH = \"C:\\\\Repos\\\\imagenet-1k\\\\training\\\\\"\n",
    "TRAINING_ANNOTATION_PATH = \"C:\\\\Repos\\\\imagenet-1k\\\\labels\\\\synsets.txt\"\n",
    "\n",
    "VALIDATION_IMAGE_PATH = \"C:\\\\Repos\\\\imagenet-1k\\\\validation\\\\\"\n",
    "VALIDATION_ANNOTATION_PATH = \"C:\\\\Repos\\\\imagenet-1k\\\\labels\\\\val_labels.txt\"\n",
    "\n",
    "training_dataset = ImageNetDataset(TRAINING_IMAGE_PATH, TRAINING_ANNOTATION_PATH, transform_image)\n",
    "validation_dataset = ImageNetDataset(VALIDATION_IMAGE_PATH, VALIDATION_ANNOTATION_PATH, transform_image)\n",
    "\n",
    "\n",
    "plt.imshow(training_dataset[0][0].permute(1, 2, 0).int())\n",
    "print(f'First image label: {training_dataset[0][1]}')\n",
    "\n",
    "plt.imshow(validation_dataset[0][0].permute(1, 2, 0).int())\n",
    "print(f'First image label: {validation_dataset[0][1]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing save weights to file directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifier import Darknet53\n",
    "\n",
    "WEIGHTS_PATH = '.\\classifer.weights'\n",
    "\n",
    "model = Darknet53(weights_path=WEIGHTS_PATH)\n",
    "\n",
    "model.save_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing loading weights from file directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifier import Darknet53\n",
    "\n",
    "WEIGHTS_PATH = '.\\classifer.weights'\n",
    "\n",
    "model = Darknet53(weights_path=WEIGHTS_PATH)\n",
    "\n",
    "model.load_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert validation localization files into direct labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "PATH = 'C:\\\\Repos\\\\imagenet-1k\\\\labels\\\\LOC_val_solution.csv'\n",
    "LABELS = 'C:\\\\Repos\\\\imagenet-1k\\\\labels\\\\synsets.txt'\n",
    "\n",
    "df = pd.read_csv(PATH)\n",
    "\n",
    "with open(LABELS, 'r') as f:\n",
    "    labels = f.readlines()\n",
    "\n",
    "#sort in order\n",
    "df = df.sort_values('ImageId')\n",
    "\n",
    "# take first label only, disgard bounding boxs\n",
    "df[\"PredictionString\"] = df[\"PredictionString\"].apply(lambda x: x.split()[0])\n",
    "df[\"PredictionString\"] = df[\"PredictionString\"].apply(lambda x: labels.index(x.strip() + '\\n'))\n",
    "df.head(20)\n",
    "\n",
    "#df['PredictionString'].to_csv('val_labels.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test validation set after 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from imagenet import ImageNetDataset\n",
    "from classifier import Darknet53\n",
    "from utils import scale\n",
    "import matplotlib.pyplot as plt\n",
    "from labels import LABELS\n",
    "\n",
    "VALIDATION_IMAGE_PATH = \"C:\\\\Repos\\\\imagenet-1k\\\\validation\\\\\"\n",
    "VALIDATION_ANNOTATION_PATH = \"C:\\\\Repos\\\\imagenet-1k\\\\labels\\\\val_labels.txt\"\n",
    "\n",
    "WEIGHTS_PATH = '.\\classifer.weights'\n",
    "\n",
    "validation_dataset = ImageNetDataset(VALIDATION_IMAGE_PATH, VALIDATION_ANNOTATION_PATH, scale)\n",
    "validation = torch.utils.data.DataLoader(validation_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "model = Darknet53(weights_path=WEIGHTS_PATH)\n",
    "model.to('cuda')\n",
    "\n",
    "# Set the classifier to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Evaluate the classifier on the test dataset\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in validation:\n",
    "\n",
    "        images = images.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.topk(outputs.data, k=1, dim=1)\n",
    "\n",
    "        # Count the number of correct predictions\n",
    "        correct += (predicted == labels.view(-1, 1)).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        print(f'Accuracy of the network on the {total} test images: {100 * correct / total}%')\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trained at 256x256 input resolution for 20 epochs with a top-1 accuracy of 65% and top-5 accuracy of 85% on the validation set.\n",
    "\n",
    "Going to up the input resolution to 416x416 and fine tune for ~10 epochs as suggested by the orginal authors of the yolov3 paper. \n",
    "\n",
    "Had to reduce batch size to 16 so the full batch can be stored/processed by VRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifier import Darknet53\n",
    "\n",
    "WEIGHTS_PATH = '.\\classifer.weights'\n",
    "\n",
    "model = Darknet53(weights_path=WEIGHTS_PATH)\n",
    "\n",
    "print(\"hi\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
